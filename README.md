# news_classification_tool
基于网络爬虫的外媒新闻分类统计工具的设计与实现

主要需求包括：

（1）能够自动爬取并显示此刻至7天前的外媒新闻

（2）能够显示每篇新闻的关键词

（3）能够对新闻进行分类

（4）能够统计每类新闻的数量，并以图表形式显示


分为三大模块：

（1）新闻爬取模块：

基于Python，使用scrapy框架爬取BBC新闻网站7日内的新闻，并存储在MongoDB中。
     为避免重复爬取新闻，设置布隆过滤器去重。由于每篇新闻的URL在网站中是唯一的，而URL中特定的数字串也是唯一的。因此将该数字串作为每篇新闻的id。每爬取一篇新闻前，先将其通过布隆过滤器检查该id是否存在，若存在，爬取下一篇，反之将该新闻存储进MongoDB中。若连续3篇新闻的id相同，则认为该网站并没有更新，爬取停止。
     BBC新闻网站已对新闻进行关键词提取，需将关键词也爬取并存储下来
     
（2）文本分类模块：

利用Latent Dirichlet Allocation（简称LDA）对爬取下来的新闻根据主题分类。为一堆新闻进行聚类（所以是非监督学习），一种topic就是一类，要聚成的topic数目是事先指定的。具体实现方式是使用Python的Gensim库。它可以用来从文档中自动提取语义主题。
分类完成后需要统计各类新闻的数目。

（3）显示模块：

基于Flask框架制作简易网站，将新闻按分类显示。并能以图表形式显示各类新闻的数目。


	
工作计划：

3.11-3.25	完成爬取模块

3.26-4.15	完成分类模块

4.16-4.30	完成显示模块

5.1-5.15	完成论文
